{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_LiVKiwqEQc8",
        "outputId": "bfbe38bb-a8ef-44ce-ac27-2bb02748d48b"
      },
      "outputs": [],
      "source": [
        "import os, glob, random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm \n",
        "\n",
        "import torch\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\n",
        "import torch.nn.functional as F    \n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "import torchvision.transforms as T\n",
        "import torchvision.transforms.functional as TF\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "try:\n",
        "    import cv2\n",
        "    _HAS_CV2 = True\n",
        "except Exception:\n",
        "    _HAS_CV2 = False\n",
        "\n",
        "print(\"cv2 available:\", _HAS_CV2)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", device)\n",
        "if device.type == \"cuda\":\n",
        "    print(\"GPU:\", torch.cuda.get_device_name(0))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fp8ufjVvEStX",
        "outputId": "468cf30d-84e6-44dd-b7f5-1f4246763b27"
      },
      "outputs": [],
      "source": [
        "BASE =  #give your folder name \n",
        "\n",
        "TRAIN_DIR = os.path.join(BASE, \"train\")\n",
        "TEST_DIR  = os.path.join(BASE, \"test\")\n",
        "\n",
        "file_list = sorted(glob.glob(os.path.join(TRAIN_DIR, \"*\")))\n",
        "\n",
        "print(\"BASE:\", BASE)\n",
        "print(\"TRAIN_DIR:\", TRAIN_DIR)\n",
        "print(\"TEST_DIR:\", TEST_DIR)\n",
        "print(\"Total number of files:\", len(file_list))\n",
        "print(\"Sample files:\", file_list[:5])\n",
        "\n",
        "IMG_SIZE = 256\n",
        "BATCH_SIZE = 4\n",
        "NUM_EPOCHS = 200\n",
        "LR = 1e-4\n",
        "NUM_WORKERS = 0\n",
        "\n",
        "MODEL_DIR = os.path.join(BASE, \"models\")\n",
        "os.makedirs(MODEL_DIR, exist_ok=True)\n",
        "\n",
        "CKPT_PATH = os.path.join(MODEL_DIR, \"batsnet.pth\")\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", DEVICE)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wvUeBFEBEc6D"
      },
      "outputs": [],
      "source": [
        "to_tensor_norm = T.Compose([\n",
        "    T.ToTensor(),\n",
        "    T.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))\n",
        "])\n",
        "def detect_seam_x(img_pil, sample_border=5):\n",
        "    arr = np.array(img_pil.convert('RGB')).astype(np.float32)\n",
        "    cols = arr.mean(axis=2).mean(axis=0)\n",
        "    diffs = np.abs(np.diff(cols))\n",
        "    if diffs.size == 0:\n",
        "        return arr.shape[1] // 2\n",
        "    sep = int(np.argmax(diffs) + 1)\n",
        "    w = arr.shape[1]\n",
        "    if sep < w*0.1 or sep > w*0.9:\n",
        "        return w // 2\n",
        "    return sep\n",
        "\n",
        "def mask_to_binary_from_color(mask_pil, dist_thresh=15, bg_border=5, morph_kernel=3):\n",
        "    arr = np.array(mask_pil.convert('RGB')).astype(np.float32)\n",
        "    H, W, _ = arr.shape\n",
        "    b = max(1, bg_border)\n",
        "    samples = []\n",
        "    samples.append(arr[:b, :b, :].reshape(-1,3))\n",
        "    samples.append(arr[:b, -b:, :].reshape(-1,3))\n",
        "    samples.append(arr[-b:, :b, :].reshape(-1,3))\n",
        "    samples.append(arr[-b:, -b:, :].reshape(-1,3))\n",
        "    samples.append(arr[:b, W//4:W//4+b, :].reshape(-1,3))\n",
        "    samples.append(arr[-b:, W//4:W//4+b, :].reshape(-1,3))\n",
        "    samples = np.concatenate(samples, axis=0)\n",
        "    bg_color = np.median(samples, axis=0).astype(np.float32)\n",
        "\n",
        "    diff = arr - bg_color[None,None,:]   \n",
        "    dist = np.linalg.norm(diff, axis=2)  \n",
        "    bin_mask = (dist > dist_thresh).astype(np.uint8)\n",
        "\n",
        "    if _HAS_CV2 and morph_kernel and morph_kernel > 0:\n",
        "        k = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (morph_kernel, morph_kernel))\n",
        "        bin_mask = cv2.morphologyEx(bin_mask, cv2.MORPH_OPEN, k)\n",
        "        bin_mask = cv2.morphologyEx(bin_mask, cv2.MORPH_CLOSE, k)\n",
        "\n",
        "    return torch.from_numpy(bin_mask.astype(np.float32)).unsqueeze(0) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gMT4N603EhV7"
      },
      "outputs": [],
      "source": [
        "class Pix2PixConcatDataset(Dataset):\n",
        "    def __init__(self, file_list, img_size=IMG_SIZE, augment=False, dist_thresh=15, morph_kernel=3):\n",
        "        self.files = file_list\n",
        "        self.img_size = img_size\n",
        "        self.augment = augment\n",
        "        self.dist_thresh = dist_thresh\n",
        "        self.morph_kernel = morph_kernel\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        p = self.files[idx]\n",
        "        img_all = Image.open(p).convert('RGB')\n",
        "        sep = detect_seam_x(img_all)\n",
        "        w, h = img_all.size\n",
        "        sep = max(1, min(sep, w-1))\n",
        "\n",
        "        left = img_all.crop((0, 0, sep, h))\n",
        "        right = img_all.crop((sep, 0, w, h))\n",
        "\n",
        "        left = TF.resize(left, (self.img_size, self.img_size), interpolation=Image.BILINEAR)\n",
        "        right = TF.resize(right, (self.img_size, self.img_size), interpolation=Image.NEAREST)\n",
        "\n",
        "        if self.augment:\n",
        "            if random.random() < 0.5:\n",
        "                left = TF.hflip(left)\n",
        "                right = TF.hflip(right)\n",
        "\n",
        "            if random.random() < 0.5:\n",
        "                left = TF.vflip(left)\n",
        "                right = TF.vflip(right)\n",
        "\n",
        "        inp_t = to_tensor_norm(left).float()  \n",
        "        tgt_t = mask_to_binary_from_color(right, dist_thresh=self.dist_thresh,\n",
        "                                          bg_border=5, morph_kernel=self.morph_kernel).float()  \n",
        "\n",
        "        return inp_t, tgt_t\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        },
        "id": "V_PG7wp_EqSN",
        "outputId": "09c9d10a-7c36-4c40-8726-cf00bd3de5e4"
      },
      "outputs": [],
      "source": [
        "DIST_THRESH = 15\n",
        "MORPH_KERNEL = 3 if _HAS_CV2 else 0\n",
        "\n",
        "ds = Pix2PixConcatDataset(file_list, img_size=IMG_SIZE, augment=True,\n",
        "                          dist_thresh=DIST_THRESH, morph_kernel=MORPH_KERNEL)\n",
        "print(\"Dataset length:\", len(ds))\n",
        "\n",
        "indices = list(range(len(ds)))\n",
        "train_idx, test_idx = train_test_split(indices, test_size=0.3, random_state=__, shuffle=True) #give random state\n",
        "\n",
        "train_loader = DataLoader(ds, batch_size=BATCH_SIZE, sampler=SubsetRandomSampler(train_idx),\n",
        "                          num_workers=NUM_WORKERS, pin_memory=True)\n",
        "test_loader  = DataLoader(ds, batch_size=BATCH_SIZE, sampler=SubsetRandomSampler(test_idx),\n",
        "                          num_workers=NUM_WORKERS, pin_memory=True)\n",
        "\n",
        "train_paths = [file_list[i] for i in train_idx]\n",
        "test_paths  = [file_list[i] for i in test_idx]\n",
        "\n",
        "print(\"Train images:\", len(train_paths))\n",
        "print(\"Test images :\", len(test_paths))\n",
        "\n",
        "print(\"\\n--- Sample train paths ---\")\n",
        "for p in train_paths[:5]:\n",
        "    print(p)\n",
        "\n",
        "print(\"\\n--- Sample test paths ---\")\n",
        "for p in test_paths[:5]:\n",
        "    print(p)\n",
        "\n",
        "images, masks = next(iter(train_loader))\n",
        "print(\"Batch shapes:\", images.shape, masks.shape)\n",
        "\n",
        "img0 = ((images[0].permute(1,2,0).numpy() * 0.5) + 0.5)\n",
        "mask0 = masks[0].squeeze(0).numpy()\n",
        "\n",
        "plt.figure(figsize=(6,3))\n",
        "plt.subplot(1,2,1); plt.imshow(img0); plt.title(\"Sample Image\"); plt.axis('off')\n",
        "plt.subplot(1,2,2); plt.imshow(mask0, cmap='gray'); plt.title(\"Sample Mask (binary)\"); plt.axis('off')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FtVthegkEsVC"
      },
      "outputs": [],
      "source": [
        "class ConvBlock(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch, stride=1):\n",
        "        super().__init__()\n",
        "        self.block = nn.Sequential(\n",
        "            nn.Conv2d(in_ch, out_ch, 3, stride=stride, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(out_ch),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.block(x)\n",
        "    \n",
        "class TextureEncoder(nn.Module):\n",
        "    def __init__(self, in_ch=3, base_ch=32):\n",
        "        super().__init__()\n",
        "        self.enc1 = ConvBlock(in_ch, base_ch)\n",
        "        self.enc2 = ConvBlock(base_ch, base_ch * 2, stride=2)\n",
        "        self.enc3 = ConvBlock(base_ch * 2, base_ch * 4, stride=2)\n",
        "        self.enc4 = ConvBlock(base_ch * 4, base_ch * 4, stride=2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.enc1(x)\n",
        "        x = self.enc2(x)\n",
        "        x = self.enc3(x)\n",
        "        x = self.enc4(x)\n",
        "        return x  \n",
        "    \n",
        "class AppearanceDeviation(nn.Module):\n",
        "    def __init__(self, channels):\n",
        "        super().__init__()\n",
        "        self.local_mean = nn.Conv2d(\n",
        "            channels, channels, kernel_size=5, padding=2, groups=channels, bias=False\n",
        "        )\n",
        "\n",
        "    def forward(self, F):\n",
        "        mu = self.local_mean(F)\n",
        "        D = torch.norm(F - mu, dim=1, keepdim=True)\n",
        "        return D\n",
        "    \n",
        "class FeatureVariance(nn.Module):\n",
        "    def __init__(self, kernel_size=5):\n",
        "        super().__init__()\n",
        "        self.pool = nn.AvgPool2d(kernel_size, stride=1, padding=kernel_size // 2)\n",
        "\n",
        "    def forward(self, F):\n",
        "        mean = self.pool(F)\n",
        "        mean_sq = self.pool(F ** 2)\n",
        "        var = mean_sq - mean ** 2\n",
        "        V = torch.mean(var, dim=1, keepdim=True)\n",
        "        return V\n",
        "    \n",
        "class TransitionEncoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(2, 16, 3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(16, 32, 3, padding=1),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, D, V):\n",
        "        T = torch.cat([D, V], dim=1)\n",
        "        return self.conv(T)\n",
        "    \n",
        "class SpatialCoherence(nn.Module):\n",
        "    def __init__(self, channels):\n",
        "        super().__init__()\n",
        "        self.d1 = nn.Conv2d(channels, channels, 3, padding=1, dilation=1)\n",
        "        self.d2 = nn.Conv2d(channels, channels, 3, padding=2, dilation=2)\n",
        "        self.d4 = nn.Conv2d(channels, channels, 3, padding=4, dilation=4)\n",
        "        self.fuse = nn.Conv2d(channels * 3, channels, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.d1(x)\n",
        "        x2 = self.d2(x)\n",
        "        x3 = self.d4(x)\n",
        "        x_cat = torch.cat([x1, x2, x3], dim=1)\n",
        "        return self.fuse(x_cat)\n",
        "\n",
        "class PTDNet(nn.Module):\n",
        "    def __init__(self, base_ch=48):\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder = TextureEncoder(in_ch=3, base_ch=base_ch)\n",
        "        enc_out_ch = base_ch * 4\n",
        "        self.dev = AppearanceDeviation(channels=enc_out_ch)\n",
        "        self.var = FeatureVariance()\n",
        "        self.trans_enc = TransitionEncoder()\n",
        "        self.coherence = SpatialCoherence(channels=32)\n",
        "        self.boundary_head = nn.Conv2d(32, 1, 1)      \n",
        "\n",
        "    def forward(self, x):\n",
        "        Fm = self.encoder(x)     \n",
        "        D = self.dev(Fm)                 \n",
        "        V = self.var(Fm)           \n",
        "        T = self.trans_enc(D, V)          \n",
        "        C = self.coherence(T)           \n",
        "        logits = self.boundary_head(C)   \n",
        "\n",
        "        logits = F.interpolate(logits, size=x.shape[2:], mode='bilinear', align_corners=False)\n",
        "\n",
        "        return logits\n",
        "\n",
        "model = PTDNet().to(DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def dice_loss(pred, target, eps=1e-6):\n",
        "    pred = pred.view(-1)\n",
        "    target = target.view(-1)\n",
        "    inter = (pred * target).sum()\n",
        "    return 1 - (2 * inter + eps) / (pred.sum() + target.sum() + eps)\n",
        "\n",
        "def soft_dice_loss(pred, target, eps=1e-6):\n",
        "    inter = (pred * target).sum(dim=(1,2,3))\n",
        "    union = pred.sum(dim=(1,2,3)) + target.sum(dim=(1,2,3))\n",
        "    dice = (2 * inter + eps) / (union + eps)\n",
        "    return 1 - dice.mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9zagHH-AFIoS"
      },
      "outputs": [],
      "source": [
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QNompL13HiLx",
        "outputId": "99558bd6-01f0-4524-a035-6d1fddd8d2ce"
      },
      "outputs": [],
      "source": [
        "best_val_loss = float('inf')\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "train_accs = []\n",
        "val_accs = []\n",
        "\n",
        "for epoch in range(1, NUM_EPOCHS + 1):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    running_correct = 0\n",
        "    running_pixels = 0\n",
        "\n",
        "    for imgs, masks in tqdm(train_loader, desc=f\"Train E{epoch}\", leave=False):\n",
        "        imgs = imgs.to(DEVICE, dtype=torch.float32)\n",
        "        masks = masks.to(DEVICE, dtype=torch.float32)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        logits, sigma = model(imgs)\n",
        "        probs = torch.sigmoid(logits)\n",
        "        preds = (probs > 0.5).float()   \n",
        "\n",
        "        running_correct += (preds.bool() == masks.bool()).sum().item()\n",
        "        running_pixels += masks.numel()\n",
        "\n",
        "        loss_bce = nn.BCEWithLogitsLoss()(logits, masks)\n",
        "        loss_dice = soft_dice_loss(probs, masks)\n",
        "\n",
        "        loss = 0.6 * loss_bce + 0.4 * loss_dice \n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item() * imgs.size(0)\n",
        "\n",
        "    train_loss = running_loss / len(train_idx)\n",
        "    train_acc = running_correct / float(running_pixels)\n",
        "    train_losses.append(train_loss)\n",
        "    train_accs.append(train_acc)\n",
        "\n",
        "    model.eval()\n",
        "    val_running = 0.0\n",
        "    val_running_correct = 0\n",
        "    val_running_pixels = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for imgs, masks in test_loader:\n",
        "            imgs = imgs.to(DEVICE, dtype=torch.float32)\n",
        "            masks = masks.to(DEVICE, dtype=torch.float32)\n",
        "\n",
        "            logits, sigma = model(imgs)\n",
        "            probs = torch.sigmoid(logits)\n",
        "            preds = (probs > 0.5).float()\n",
        "\n",
        "            val_running_correct += (preds.bool() == masks.bool()).sum().item()\n",
        "            val_running_pixels += masks.numel()\n",
        "\n",
        "            loss_bce = nn.BCEWithLogitsLoss()(logits, masks)\n",
        "            loss_dice = soft_dice_loss(probs, masks)\n",
        "\n",
        "            val_loss_batch = 0.6 * loss_bce + 0.4 * loss_dice \n",
        "\n",
        "            val_running += val_loss_batch.item() * imgs.size(0)\n",
        "\n",
        "    val_loss = val_running / len(test_idx)\n",
        "    val_acc = val_running_correct / float(val_running_pixels)\n",
        "\n",
        "    val_losses.append(val_loss)\n",
        "    val_accs.append(val_acc)\n",
        "\n",
        "    scheduler.step(val_loss)\n",
        "\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'val_loss': val_loss\n",
        "        }, CKPT_PATH)\n",
        "\n",
        "    print(f\"Epoch {epoch}/{NUM_EPOCHS} | train_loss={train_loss:.4f} | val_loss={val_loss:.4f} | train_acc={train_acc:.4f} | val_acc={val_acc:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "out_dir = globals().get(\"MODEL_DIR\", \".\")\n",
        "os.makedirs(out_dir, exist_ok=True)\n",
        "out_path = os.path.join(out_dir, \"loss_and_acc_curve.png\")\n",
        "\n",
        "epochs = np.arange(1, len(train_losses) + 1)\n",
        "train_losses = np.array(train_losses)\n",
        "val_losses = np.array(val_losses)\n",
        "train_accs = np.array(train_accs)\n",
        "val_accs = np.array(val_accs)\n",
        "\n",
        "def smooth(x, window=5):\n",
        "    if len(x) < window:\n",
        "        return x\n",
        "    kernel = np.ones(window) / window\n",
        "    return np.convolve(x, kernel, mode=\"same\")\n",
        "\n",
        "train_losses_s = smooth(train_losses, window=5)\n",
        "val_losses_s = smooth(val_losses, window=5)\n",
        "train_accs_s = smooth(train_accs, window=5)\n",
        "val_accs_s = smooth(val_accs, window=5)\n",
        "\n",
        "plt.figure(figsize=(12,4))\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(epochs, train_losses, label='Train loss (raw)', alpha=0.3)\n",
        "plt.plot(epochs, val_losses, label='Val loss (raw)', alpha=0.3)\n",
        "best_epoch = int(np.argmin(val_losses)) + 1\n",
        "plt.scatter([best_epoch], [val_losses.min()], color='red', zorder=10, label=f'Best val (ep {best_epoch})')\n",
        "plt.xlabel('Epoch'); plt.ylabel('Loss'); plt.title('Loss vs Epoch')\n",
        "plt.legend(); plt.grid(alpha=0.2)\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(epochs, train_accs, label='Train acc (raw)', alpha=0.3)\n",
        "plt.plot(epochs, val_accs, label='Val acc (raw)', alpha=0.3)\n",
        "best_acc_epoch = int(np.argmax(val_accs)) + 1\n",
        "plt.scatter([best_acc_epoch], [val_accs.max()], color='red', zorder=10, label=f'Best val acc (ep {best_acc_epoch})')\n",
        "plt.xlabel('Epoch'); plt.ylabel('Accuracy'); plt.title('Pixel-wise Accuracy vs Epoch')\n",
        "plt.ylim(0.0, 1.0)\n",
        "plt.legend(); plt.grid(alpha=0.2)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(out_path, dpi=150)\n",
        "print(\"Saved loss+accuracy plot to:\", out_path)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.save({\n",
        "    'model_state_dict': model.state_dict(),\n",
        "    'optimizer_state_dict': optimizer.state_dict(),\n",
        "    'epoch': NUM_EPOCHS\n",
        "}, CKPT_PATH)\n",
        "\n",
        "print(\"Model saved successfully at:\", CKPT_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "iACMjlvfrJS1",
        "outputId": "f99ea27a-202a-406e-8b78-5b09950aab36"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "ckpt = torch.load(CKPT_PATH, map_location=DEVICE)\n",
        "if 'model_state_dict' in ckpt:\n",
        "    model.load_state_dict(ckpt['model_state_dict'])\n",
        "model.to(DEVICE); model.eval()\n",
        "\n",
        "idx = random.choice(test_idx)\n",
        "test_img, test_mask = ds[idx]\n",
        "inp = test_img.unsqueeze(0).to(DEVICE)\n",
        "\n",
        "with torch.no_grad():\n",
        "    logits, sigma = model(inp)\n",
        "    probs = torch.sigmoid(logits)\n",
        "\n",
        "prob_map = probs[0,0].cpu().numpy()\n",
        "pred_bin = (prob_map > 0.5).astype(float)\n",
        "gt_map = test_mask.squeeze(0).numpy()\n",
        "\n",
        "inp_vis = ((test_img.permute(1,2,0).numpy() * 0.5) + 0.5)\n",
        "\n",
        "plt.figure(figsize=(10,4))\n",
        "plt.subplot(1,3,1); plt.imshow(inp_vis); plt.title(\"Input\"); plt.axis('off')\n",
        "plt.subplot(1,3,2); plt.imshow(gt_map, cmap='gray'); plt.title(\"GT\"); plt.axis('off')\n",
        "plt.subplot(1,3,3); plt.imshow(pred_bin, cmap='gray'); plt.title(\"Pred\"); plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_ds = Pix2PixConcatDataset(\n",
        "    test_paths,\n",
        "    img_size=IMG_SIZE,\n",
        "    augment=False,\n",
        "    dist_thresh=DIST_THRESH,\n",
        "    morph_kernel=MORPH_KERNEL\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    test_ds,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    num_workers=NUM_WORKERS,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "print(\"Test dataset length:\", len(test_ds))\n",
        "\n",
        "eps = 1e-6\n",
        "\n",
        "acc_per_image = []\n",
        "iou_per_image = []\n",
        "precision_per_image = []\n",
        "recall_per_image = []\n",
        "sensitivity_per_image = []\n",
        "dice_per_image = []\n",
        "\n",
        "preds_list = []\n",
        "gts_list = []\n",
        "imgs_list = []\n",
        "paths_list = []\n",
        "\n",
        "model.eval()\n",
        "global_idx = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for imgs, masks in tqdm(test_loader, desc=\"Evaluate\"):\n",
        "        imgs = imgs.to(DEVICE, dtype=torch.float32)\n",
        "        masks = masks.to(DEVICE, dtype=torch.float32)\n",
        "\n",
        "        logits1= model(imgs)\n",
        "        probs1 = torch.sigmoid(logits1)\n",
        "\n",
        "        imgs_flip = torch.flip(imgs, [3])\n",
        "        logits2 = model(imgs_flip)\n",
        "        probs2 = torch.sigmoid(logits2)\n",
        "        probs2 = torch.flip(probs2, [3])\n",
        "\n",
        "        probs = (probs1 + probs2) / 2\n",
        "        preds = (probs > 0.5).float()\n",
        "\n",
        "\n",
        "        B = imgs.size(0)\n",
        "        H, W = masks.shape[2], masks.shape[3]\n",
        "\n",
        "        for i in range(B):\n",
        "            pred_i = preds[i, 0].cpu().numpy().astype(np.float32).ravel()\n",
        "            gt_i   = masks[i, 0].cpu().numpy().astype(np.float32).ravel()\n",
        "\n",
        "            TP = (pred_i * gt_i).sum()\n",
        "            FP = (pred_i * (1 - gt_i)).sum()\n",
        "            FN = ((1 - pred_i) * gt_i).sum()\n",
        "            TN = ((1 - pred_i) * (1 - gt_i)).sum()\n",
        "\n",
        "            acc = (TP + TN) / (TP + TN + FP + FN + eps)\n",
        "            union = TP + FP + FN\n",
        "            iou = (TP + eps) / (union + eps)\n",
        "            precision = (TP + eps) / (TP + FP + eps)\n",
        "            recall = (TP + eps) / (TP + FN + eps)\n",
        "            sensitivity = recall\n",
        "            dice = (2 * TP + eps) / ((pred_i.sum() + gt_i.sum()) + eps)\n",
        "\n",
        "            acc_per_image.append(acc)\n",
        "            iou_per_image.append(iou)\n",
        "            precision_per_image.append(precision)\n",
        "            recall_per_image.append(recall)\n",
        "            sensitivity_per_image.append(sensitivity)\n",
        "            dice_per_image.append(dice)\n",
        "\n",
        "            try:\n",
        "                imgs_list.append(((imgs[i].cpu().permute(1,2,0).numpy() * 0.5) + 0.5))\n",
        "            except:\n",
        "                imgs_list.append(None)\n",
        "\n",
        "            preds_list.append(pred_i.reshape(H, W))\n",
        "            gts_list.append(gt_i.reshape(H, W))\n",
        "            paths_list.append(test_paths[global_idx])\n",
        "\n",
        "            global_idx += 1\n",
        "\n",
        "acc_per_image = np.array(acc_per_image)\n",
        "iou_per_image = np.array(iou_per_image)\n",
        "precision_per_image = np.array(precision_per_image)\n",
        "recall_per_image = np.array(recall_per_image)\n",
        "sensitivity_per_image = np.array(sensitivity_per_image)\n",
        "dice_per_image = np.array(dice_per_image)\n",
        "\n",
        "print(\"\\n===== Per-image Test Results =====\")\n",
        "print(f\"Accuracy:    mean={acc_per_image.mean():.4f}  std={acc_per_image.std():.4f}\")\n",
        "print(f\"IoU:         mean={iou_per_image.mean():.4f}  std={iou_per_image.std():.4f}\")\n",
        "print(f\"Precision:   mean={precision_per_image.mean():.4f}  std={precision_per_image.std():.4f}\")\n",
        "print(f\"Recall:      mean={recall_per_image.mean():.4f}  std={recall_per_image.std():.4f}\")\n",
        "print(f\"Sensitivity: mean={sensitivity_per_image.mean():.4f}  std={sensitivity_per_image.std():.4f}\")\n",
        "print(f\"Dice:        mean={dice_per_image.mean():.4f}  std={dice_per_image.std():.4f}\")\n",
        "\n",
        "plt.figure(figsize=(12,5))\n",
        "plt.plot(dice_per_image, label=\"Dice\")\n",
        "plt.plot(iou_per_image, label=\"IoU\")\n",
        "plt.plot(precision_per_image, label=\"Precision\")\n",
        "plt.plot(recall_per_image, label=\"Recall\")\n",
        "plt.plot(sensitivity_per_image, label=\"Sensitivity\")\n",
        "plt.plot(acc_per_image, label=\"Accuracy\")\n",
        "\n",
        "plt.xlabel(\"Test image index\")\n",
        "plt.ylabel(\"Metric value\")\n",
        "plt.ylim(-0.05, 1.05)\n",
        "plt.legend()\n",
        "plt.title(\"Per-image metrics on test set\")\n",
        "plt.grid(alpha=0.2)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "n_show = 4\n",
        "sorted_idx = np.argsort(dice_per_image)\n",
        "worst_idx = sorted_idx[:n_show]\n",
        "best_idx  = sorted_idx[-n_show:][::-1]\n",
        "\n",
        "def show_cases(idxs, title_prefix=\"Case\"):\n",
        "    plt.figure(figsize=(4 * len(idxs), 4))\n",
        "    for k, idx in enumerate(idxs):\n",
        "        img = imgs_list[idx]\n",
        "        pred = preds_list[idx]\n",
        "        gt = gts_list[idx]\n",
        "        path = os.path.basename(paths_list[idx])\n",
        "\n",
        "        plt.subplot(1, len(idxs), k+1)\n",
        "        if img is not None:\n",
        "            plt.imshow(img)\n",
        "            plt.imshow(pred, cmap='gray', alpha=0.45)\n",
        "            plt.contour(gt, colors='r', linewidths=0.5)\n",
        "        else:\n",
        "            plt.imshow(pred, cmap='gray')\n",
        "            plt.contour(gt, colors='r', linewidths=0.5)\n",
        "\n",
        "        plt.title(f\"{title_prefix}\\n{path}\\nDice={dice_per_image[idx]:.3f}\")\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "print(\"\\nShowing worst cases:\", worst_idx.tolist())\n",
        "show_cases(worst_idx, title_prefix=\"Worst\")\n",
        "\n",
        "print(\"\\nShowing best cases:\", best_idx.tolist())\n",
        "show_cases(best_idx, title_prefix=\"Best\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv (3.11.5)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
